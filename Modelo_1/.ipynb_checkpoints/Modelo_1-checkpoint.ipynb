{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('Parâmetros_de_todos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura (m)</th>\n",
       "      <th>Comprimento médio passo completo</th>\n",
       "      <th>Erro absoluto médio do comprimento de passo em metros</th>\n",
       "      <th>Desvio padrão comprimento passo medido em metros</th>\n",
       "      <th>Desvio padrão do erro de comprimento de passo em metros</th>\n",
       "      <th>Comprimento médio de meio passo em metros</th>\n",
       "      <th>Erro absoluto médio do meio comprimento de passo em metros</th>\n",
       "      <th>Desvio padrão do comprimento médio de meio passo em metros</th>\n",
       "      <th>Desvio padrão do erro de comprimento de meio passo em metros</th>\n",
       "      <th>Comprimento do Swing em metros</th>\n",
       "      <th>...</th>\n",
       "      <th>Distância inicial do pé em metros</th>\n",
       "      <th>Erro absoluto médio da distância entre os pés em metros</th>\n",
       "      <th>Desvio padrão da distância inicial entre os pés</th>\n",
       "      <th>Desvio padrão do erro da distância inicial entre os pés em metros</th>\n",
       "      <th>Ângulo real de abertura das pernas em graus</th>\n",
       "      <th>Ângulo médio de abertura das pernas em graus</th>\n",
       "      <th>Erro absoluto médio do angulo entre as pernas em graus</th>\n",
       "      <th>Desvio padrão do ângulo médio dos passos em graus</th>\n",
       "      <th>Número de amostras do ângulo</th>\n",
       "      <th>Deficiência</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.7690</td>\n",
       "      <td>1.0644</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.5281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>33.8671</td>\n",
       "      <td>27.1121</td>\n",
       "      <td>6.7549</td>\n",
       "      <td>6.5828</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.7463</td>\n",
       "      <td>1.0707</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>29.8176</td>\n",
       "      <td>26.8024</td>\n",
       "      <td>3.0153</td>\n",
       "      <td>9.3831</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.7394</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>28.0941</td>\n",
       "      <td>25.1114</td>\n",
       "      <td>2.9827</td>\n",
       "      <td>6.5802</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.7448</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>33.8671</td>\n",
       "      <td>25.4250</td>\n",
       "      <td>8.4420</td>\n",
       "      <td>7.9330</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.7532</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.3203</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>33.8671</td>\n",
       "      <td>23.1380</td>\n",
       "      <td>10.7291</td>\n",
       "      <td>8.2333</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.7237</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.4240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>28.0941</td>\n",
       "      <td>22.9306</td>\n",
       "      <td>5.1635</td>\n",
       "      <td>5.1038</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.7317</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.4079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>20.0455</td>\n",
       "      <td>2.3476</td>\n",
       "      <td>5.2166</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.6871</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>20.2036</td>\n",
       "      <td>2.1894</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.7292</td>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.3386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>18.3793</td>\n",
       "      <td>4.0137</td>\n",
       "      <td>4.4645</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.7244</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>18.7675</td>\n",
       "      <td>3.6255</td>\n",
       "      <td>3.7123</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.7256</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>18.9055</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>4.3688</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.7175</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>21.0406</td>\n",
       "      <td>1.3524</td>\n",
       "      <td>3.3947</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.7162</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.3939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>20.6005</td>\n",
       "      <td>1.7925</td>\n",
       "      <td>3.3350</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.7338</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>20.3442</td>\n",
       "      <td>2.0488</td>\n",
       "      <td>3.0907</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.4250</td>\n",
       "      <td>0.7924</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>26.5806</td>\n",
       "      <td>24.4826</td>\n",
       "      <td>2.0981</td>\n",
       "      <td>5.0958</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.7091</td>\n",
       "      <td>1.0133</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>26.3770</td>\n",
       "      <td>25.9638</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>5.3478</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.6873</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>20.1291</td>\n",
       "      <td>20.3752</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>2.8405</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.6914</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>20.1291</td>\n",
       "      <td>20.2362</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>3.5788</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.6735</td>\n",
       "      <td>0.7479</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>19.9958</td>\n",
       "      <td>2.3972</td>\n",
       "      <td>2.3565</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.6079</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.3628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>19.4980</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>2.1838</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.6964</td>\n",
       "      <td>0.7711</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.3856</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>20.4787</td>\n",
       "      <td>1.9144</td>\n",
       "      <td>2.5841</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.7179</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>21.0872</td>\n",
       "      <td>1.3058</td>\n",
       "      <td>5.4974</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.7153</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>21.2856</td>\n",
       "      <td>1.1074</td>\n",
       "      <td>1.5333</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.7561</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>22.6155</td>\n",
       "      <td>18.7064</td>\n",
       "      <td>3.9091</td>\n",
       "      <td>3.2850</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.6845</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>22.6155</td>\n",
       "      <td>20.3555</td>\n",
       "      <td>2.2600</td>\n",
       "      <td>2.5311</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.7069</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>22.6155</td>\n",
       "      <td>21.3530</td>\n",
       "      <td>1.2625</td>\n",
       "      <td>1.5360</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.6962</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>22.3930</td>\n",
       "      <td>21.1445</td>\n",
       "      <td>1.2486</td>\n",
       "      <td>2.5183</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.4312</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>26.5806</td>\n",
       "      <td>23.3593</td>\n",
       "      <td>3.2214</td>\n",
       "      <td>2.9807</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Altura (m)  Comprimento médio passo completo  \\\n",
       "0       1.7690                            1.0644   \n",
       "1       1.7463                            1.0707   \n",
       "2       1.7394                            0.9800   \n",
       "3       1.7448                            0.9973   \n",
       "4       1.7532                            0.9237   \n",
       "5       1.7237                            0.8789   \n",
       "6       1.7317                            0.7449   \n",
       "7       1.6871                            0.7648   \n",
       "8       1.7292                            0.6887   \n",
       "9       1.7244                            0.7030   \n",
       "10      1.7256                            0.7174   \n",
       "11      1.7175                            0.7886   \n",
       "12      1.7162                            0.7770   \n",
       "13      1.7338                            0.7755   \n",
       "14      1.4250                            0.7924   \n",
       "15      1.7091                            1.0133   \n",
       "16      1.6873                            0.7727   \n",
       "17      1.6914                            0.7634   \n",
       "18      1.6735                            0.7479   \n",
       "19      1.6079                            0.7306   \n",
       "20      1.6964                            0.7711   \n",
       "21      1.7179                            0.8048   \n",
       "22      1.7153                            0.8040   \n",
       "23      1.7561                            0.6931   \n",
       "24      1.6845                            0.7756   \n",
       "25      1.7069                            0.7982   \n",
       "26      1.6962                            0.7985   \n",
       "27      1.4312                            0.7539   \n",
       "\n",
       "    Erro absoluto médio do comprimento de passo em metros  \\\n",
       "0                                              0.1356       \n",
       "1                                              0.0007       \n",
       "2                                              0.0200       \n",
       "3                                              0.2027       \n",
       "4                                              0.2763       \n",
       "5                                              0.1211       \n",
       "6                                              0.0551       \n",
       "7                                              0.0352       \n",
       "8                                              0.1113       \n",
       "9                                              0.0970       \n",
       "10                                             0.0826       \n",
       "11                                             0.0114       \n",
       "12                                             0.0230       \n",
       "13                                             0.0245       \n",
       "14                                             0.0076       \n",
       "15                                             0.0733       \n",
       "16                                             0.1373       \n",
       "17                                             0.1466       \n",
       "18                                             0.0521       \n",
       "19                                             0.0694       \n",
       "20                                             0.0289       \n",
       "21                                             0.0048       \n",
       "22                                             0.0040       \n",
       "23                                             0.0769       \n",
       "24                                             0.0056       \n",
       "25                                             0.0018       \n",
       "26                                             0.0015       \n",
       "27                                             0.0461       \n",
       "\n",
       "    Desvio padrão comprimento passo medido em metros  \\\n",
       "0                                             0.2450   \n",
       "1                                             0.3917   \n",
       "2                                             0.2718   \n",
       "3                                             0.3144   \n",
       "4                                             0.3203   \n",
       "5                                             0.1916   \n",
       "6                                             0.2055   \n",
       "7                                             0.0245   \n",
       "8                                             0.1710   \n",
       "9                                             0.1434   \n",
       "10                                            0.1598   \n",
       "11                                            0.1116   \n",
       "12                                            0.1136   \n",
       "13                                            0.1029   \n",
       "14                                            0.1462   \n",
       "15                                            0.2119   \n",
       "16                                            0.0687   \n",
       "17                                            0.1170   \n",
       "18                                            0.0489   \n",
       "19                                            0.0454   \n",
       "20                                            0.0878   \n",
       "21                                            0.1652   \n",
       "22                                            0.0627   \n",
       "23                                            0.1133   \n",
       "24                                            0.0475   \n",
       "25                                            0.0518   \n",
       "26                                            0.0683   \n",
       "27                                            0.0628   \n",
       "\n",
       "    Desvio padrão do erro de comprimento de passo em metros  \\\n",
       "0                                                0.21         \n",
       "1                                                0.20         \n",
       "2                                                0.18         \n",
       "3                                                0.28         \n",
       "4                                                0.32         \n",
       "5                                                0.13         \n",
       "6                                                0.14         \n",
       "7                                                0.02         \n",
       "8                                                0.16         \n",
       "9                                                0.14         \n",
       "10                                               0.13         \n",
       "11                                               0.09         \n",
       "12                                               0.08         \n",
       "13                                               0.09         \n",
       "14                                               0.08         \n",
       "15                                               0.11         \n",
       "16                                               0.05         \n",
       "17                                               0.07         \n",
       "18                                               0.03         \n",
       "19                                               0.04         \n",
       "20                                               0.06         \n",
       "21                                               0.08         \n",
       "22                                               0.04         \n",
       "23                                               0.11         \n",
       "24                                               0.02         \n",
       "25                                               0.03         \n",
       "26                                               0.05         \n",
       "27                                               0.06         \n",
       "\n",
       "    Comprimento médio de meio passo em metros  \\\n",
       "0                                      0.5347   \n",
       "1                                      0.5353   \n",
       "2                                      0.4900   \n",
       "3                                      0.4996   \n",
       "4                                      0.4500   \n",
       "5                                      0.4394   \n",
       "6                                      0.3791   \n",
       "7                                      0.3791   \n",
       "8                                      0.3443   \n",
       "9                                      0.3515   \n",
       "10                                     0.3549   \n",
       "11                                     0.3976   \n",
       "12                                     0.3885   \n",
       "13                                     0.3830   \n",
       "14                                     0.3996   \n",
       "15                                     0.5067   \n",
       "16                                     0.3836   \n",
       "17                                     0.3817   \n",
       "18                                     0.3756   \n",
       "19                                     0.3653   \n",
       "20                                     0.3856   \n",
       "21                                     0.4024   \n",
       "22                                     0.4016   \n",
       "23                                     0.3466   \n",
       "24                                     0.3792   \n",
       "25                                     0.3991   \n",
       "26                                     0.3992   \n",
       "27                                     0.3769   \n",
       "\n",
       "    Erro absoluto médio do meio comprimento de passo em metros  \\\n",
       "0                                              0.0653            \n",
       "1                                              0.0003            \n",
       "2                                              0.0100            \n",
       "3                                              0.1004            \n",
       "4                                              0.1500            \n",
       "5                                              0.0606            \n",
       "6                                              0.0209            \n",
       "7                                              0.0209            \n",
       "8                                              0.0557            \n",
       "9                                              0.0485            \n",
       "10                                             0.0451            \n",
       "11                                             0.0024            \n",
       "12                                             0.0115            \n",
       "13                                             0.0170            \n",
       "14                                             0.0004            \n",
       "15                                             0.0367            \n",
       "16                                             0.0714            \n",
       "17                                             0.0733            \n",
       "18                                             0.0244            \n",
       "19                                             0.0347            \n",
       "20                                             0.0144            \n",
       "21                                             0.0024            \n",
       "22                                             0.0016            \n",
       "23                                             0.0384            \n",
       "24                                             0.0058            \n",
       "25                                             0.0009            \n",
       "26                                             0.0008            \n",
       "27                                             0.0231            \n",
       "\n",
       "    Desvio padrão do comprimento médio de meio passo em metros  \\\n",
       "0                                              0.1400            \n",
       "1                                              0.2008            \n",
       "2                                              0.1423            \n",
       "3                                              0.1671            \n",
       "4                                              0.1710            \n",
       "5                                              0.1054            \n",
       "6                                              0.1045            \n",
       "7                                              0.0148            \n",
       "8                                              0.0875            \n",
       "9                                              0.0730            \n",
       "10                                             0.0867            \n",
       "11                                             0.0680            \n",
       "12                                             0.0668            \n",
       "13                                             0.0614            \n",
       "14                                             0.0910            \n",
       "15                                             0.1167            \n",
       "16                                             0.0588            \n",
       "17                                             0.0781            \n",
       "18                                             0.0489            \n",
       "19                                             0.0446            \n",
       "20                                             0.0530            \n",
       "21                                             0.1238            \n",
       "22                                             0.0319            \n",
       "23                                             0.0642            \n",
       "24                                             0.0500            \n",
       "25                                             0.0314            \n",
       "26                                             0.0521            \n",
       "27                                             0.0535            \n",
       "\n",
       "    Desvio padrão do erro de comprimento de meio passo em metros  \\\n",
       "0                                              0.1254              \n",
       "1                                              0.1102              \n",
       "2                                              0.0978              \n",
       "3                                              0.1472              \n",
       "4                                              0.1693              \n",
       "5                                              0.0781              \n",
       "6                                              0.0737              \n",
       "7                                              0.0137              \n",
       "8                                              0.0763              \n",
       "9                                              0.0654              \n",
       "10                                             0.0670              \n",
       "11                                             0.0496              \n",
       "12                                             0.0496              \n",
       "13                                             0.0486              \n",
       "14                                             0.0543              \n",
       "15                                             0.0543              \n",
       "16                                             0.0470              \n",
       "17                                             0.0504              \n",
       "18                                             0.0341              \n",
       "19                                             0.0348              \n",
       "20                                             0.0367              \n",
       "21                                             0.0911              \n",
       "22                                             0.0200              \n",
       "23                                             0.0549              \n",
       "24                                             0.0381              \n",
       "25                                             0.0204              \n",
       "26                                             0.0303              \n",
       "27                                             0.0363              \n",
       "\n",
       "    Comprimento do Swing em metros  ...  Distância inicial do pé em metros  \\\n",
       "0                           0.5281  ...                             0.1600   \n",
       "1                           0.5401  ...                             0.1941   \n",
       "2                           0.5100  ...                             0.1414   \n",
       "3                           0.5232  ...                             0.1572   \n",
       "4                           0.4580  ...                             0.1731   \n",
       "5                           0.4240  ...                             0.1758   \n",
       "6                           0.4079  ...                             0.1990   \n",
       "7                           0.3801  ...                             0.1309   \n",
       "8                           0.3386  ...                             0.1800   \n",
       "9                           0.3503  ...                             0.2091   \n",
       "10                          0.3487  ...                             0.1847   \n",
       "11                          0.3991  ...                             0.2070   \n",
       "12                          0.3939  ...                             0.2265   \n",
       "13                          0.3788  ...                             0.2059   \n",
       "14                          0.4328  ...                             0.2341   \n",
       "15                          0.4933  ...                             0.2413   \n",
       "16                          0.3774  ...                             0.1432   \n",
       "17                          0.3955  ...                             0.1407   \n",
       "18                          0.3585  ...                             0.1605   \n",
       "19                          0.3628  ...                             0.1805   \n",
       "20                          0.3913  ...                             0.1605   \n",
       "21                          0.3778  ...                             0.1482   \n",
       "22                          0.4007  ...                             0.0833   \n",
       "23                          0.3345  ...                             0.2178   \n",
       "24                          0.3745  ...                             0.1046   \n",
       "25                          0.4000  ...                             0.0849   \n",
       "26                          0.3998  ...                             0.1813   \n",
       "27                          0.3630  ...                             0.1745   \n",
       "\n",
       "    Erro absoluto médio da distância entre os pés em metros  \\\n",
       "0                                              0.0150         \n",
       "1                                              0.0191         \n",
       "2                                              0.0336         \n",
       "3                                              0.0178         \n",
       "4                                              0.0019         \n",
       "5                                              0.0008         \n",
       "6                                              0.0240         \n",
       "7                                              0.0441         \n",
       "8                                              0.0050         \n",
       "9                                              0.0241         \n",
       "10                                             0.0097         \n",
       "11                                             0.1020         \n",
       "12                                             0.1215         \n",
       "13                                             0.0309         \n",
       "14                                             0.0491         \n",
       "15                                             0.0563         \n",
       "16                                             0.0418         \n",
       "17                                             0.0343         \n",
       "18                                             0.0245         \n",
       "19                                             0.0045         \n",
       "20                                             0.0245         \n",
       "21                                             0.0368         \n",
       "22                                             0.1017         \n",
       "23                                             0.0328         \n",
       "24                                             0.0804         \n",
       "25                                             0.1001         \n",
       "26                                             0.0037         \n",
       "27                                             0.0105         \n",
       "\n",
       "    Desvio padrão da distância inicial entre os pés  \\\n",
       "0                                            0.0075   \n",
       "1                                            0.0096   \n",
       "2                                            0.0168   \n",
       "3                                            0.0089   \n",
       "4                                            0.0009   \n",
       "5                                            0.0004   \n",
       "6                                            0.0120   \n",
       "7                                            0.0221   \n",
       "8                                            0.0025   \n",
       "9                                            0.0120   \n",
       "10                                           0.0048   \n",
       "11                                           0.0510   \n",
       "12                                           0.0608   \n",
       "13                                           0.0155   \n",
       "14                                           0.0245   \n",
       "15                                           0.0281   \n",
       "16                                           0.0209   \n",
       "17                                           0.0171   \n",
       "18                                           0.0123   \n",
       "19                                           0.0023   \n",
       "20                                           0.0122   \n",
       "21                                           0.0184   \n",
       "22                                           0.0508   \n",
       "23                                           0.0164   \n",
       "24                                           0.0402   \n",
       "25                                           0.0500   \n",
       "26                                           0.0019   \n",
       "27                                           0.0053   \n",
       "\n",
       "    Desvio padrão do erro da distância inicial entre os pés em metros  \\\n",
       "0                                              0.0075                   \n",
       "1                                              0.0096                   \n",
       "2                                              0.0168                   \n",
       "3                                              0.0089                   \n",
       "4                                              0.0009                   \n",
       "5                                              0.0004                   \n",
       "6                                              0.0120                   \n",
       "7                                              0.0221                   \n",
       "8                                              0.0025                   \n",
       "9                                              0.0120                   \n",
       "10                                             0.0048                   \n",
       "11                                             0.0510                   \n",
       "12                                             0.0608                   \n",
       "13                                             0.0155                   \n",
       "14                                             0.0245                   \n",
       "15                                             0.0281                   \n",
       "16                                             0.0209                   \n",
       "17                                             0.0171                   \n",
       "18                                             0.0123                   \n",
       "19                                             0.0023                   \n",
       "20                                             0.0122                   \n",
       "21                                             0.0184                   \n",
       "22                                             0.0508                   \n",
       "23                                             0.0164                   \n",
       "24                                             0.0402                   \n",
       "25                                             0.0500                   \n",
       "26                                             0.0019                   \n",
       "27                                             0.0053                   \n",
       "\n",
       "    Ângulo real de abertura das pernas em graus  \\\n",
       "0                                       33.8671   \n",
       "1                                       29.8176   \n",
       "2                                       28.0941   \n",
       "3                                       33.8671   \n",
       "4                                       33.8671   \n",
       "5                                       28.0941   \n",
       "6                                       22.3930   \n",
       "7                                       22.3930   \n",
       "8                                       22.3930   \n",
       "9                                       22.3930   \n",
       "10                                      22.3930   \n",
       "11                                      22.3930   \n",
       "12                                      22.3930   \n",
       "13                                      22.3930   \n",
       "14                                      26.5806   \n",
       "15                                      26.3770   \n",
       "16                                      20.1291   \n",
       "17                                      20.1291   \n",
       "18                                      22.3930   \n",
       "19                                      22.3930   \n",
       "20                                      22.3930   \n",
       "21                                      22.3930   \n",
       "22                                      22.3930   \n",
       "23                                      22.6155   \n",
       "24                                      22.6155   \n",
       "25                                      22.6155   \n",
       "26                                      22.3930   \n",
       "27                                      26.5806   \n",
       "\n",
       "    Ângulo médio de abertura das pernas em graus  \\\n",
       "0                                        27.1121   \n",
       "1                                        26.8024   \n",
       "2                                        25.1114   \n",
       "3                                        25.4250   \n",
       "4                                        23.1380   \n",
       "5                                        22.9306   \n",
       "6                                        20.0455   \n",
       "7                                        20.2036   \n",
       "8                                        18.3793   \n",
       "9                                        18.7675   \n",
       "10                                       18.9055   \n",
       "11                                       21.0406   \n",
       "12                                       20.6005   \n",
       "13                                       20.3442   \n",
       "14                                       24.4826   \n",
       "15                                       25.9638   \n",
       "16                                       20.3752   \n",
       "17                                       20.2362   \n",
       "18                                       19.9958   \n",
       "19                                       19.4980   \n",
       "20                                       20.4787   \n",
       "21                                       21.0872   \n",
       "22                                       21.2856   \n",
       "23                                       18.7064   \n",
       "24                                       20.3555   \n",
       "25                                       21.3530   \n",
       "26                                       21.1445   \n",
       "27                                       23.3593   \n",
       "\n",
       "    Erro absoluto médio do angulo entre as pernas em graus  \\\n",
       "0                                              6.7549        \n",
       "1                                              3.0153        \n",
       "2                                              2.9827        \n",
       "3                                              8.4420        \n",
       "4                                             10.7291        \n",
       "5                                              5.1635        \n",
       "6                                              2.3476        \n",
       "7                                              2.1894        \n",
       "8                                              4.0137        \n",
       "9                                              3.6255        \n",
       "10                                             3.4875        \n",
       "11                                             1.3524        \n",
       "12                                             1.7925        \n",
       "13                                             2.0488        \n",
       "14                                             2.0981        \n",
       "15                                             0.4132        \n",
       "16                                             0.2461        \n",
       "17                                             0.1071        \n",
       "18                                             2.3972        \n",
       "19                                             2.8950        \n",
       "20                                             1.9144        \n",
       "21                                             1.3058        \n",
       "22                                             1.1074        \n",
       "23                                             3.9091        \n",
       "24                                             2.2600        \n",
       "25                                             1.2625        \n",
       "26                                             1.2486        \n",
       "27                                             3.2214        \n",
       "\n",
       "    Desvio padrão do ângulo médio dos passos em graus  \\\n",
       "0                                              6.5828   \n",
       "1                                              9.3831   \n",
       "2                                              6.5802   \n",
       "3                                              7.9330   \n",
       "4                                              8.2333   \n",
       "5                                              5.1038   \n",
       "6                                              5.2166   \n",
       "7                                              0.7269   \n",
       "8                                              4.4645   \n",
       "9                                              3.7123   \n",
       "10                                             4.3688   \n",
       "11                                             3.3947   \n",
       "12                                             3.3350   \n",
       "13                                             3.0907   \n",
       "14                                             5.0958   \n",
       "15                                             5.3478   \n",
       "16                                             2.8405   \n",
       "17                                             3.5788   \n",
       "18                                             2.3565   \n",
       "19                                             2.1838   \n",
       "20                                             2.5841   \n",
       "21                                             5.4974   \n",
       "22                                             1.5333   \n",
       "23                                             3.2850   \n",
       "24                                             2.5311   \n",
       "25                                             1.5360   \n",
       "26                                             2.5183   \n",
       "27                                             2.9807   \n",
       "\n",
       "    Número de amostras do ângulo  Deficiência  \n",
       "0                             15            0  \n",
       "1                              8            0  \n",
       "2                             18            0  \n",
       "3                             21            0  \n",
       "4                             23            0  \n",
       "5                             12            0  \n",
       "6                              9            0  \n",
       "7                              7            0  \n",
       "8                             18            0  \n",
       "9                             20            0  \n",
       "10                            33            0  \n",
       "11                            31            0  \n",
       "12                            32            0  \n",
       "13                            31            0  \n",
       "14                            23            1  \n",
       "15                            48            0  \n",
       "16                            23            0  \n",
       "17                            26            0  \n",
       "18                            29            0  \n",
       "19                            30            0  \n",
       "20                            22            0  \n",
       "21                            22            0  \n",
       "22                            25            0  \n",
       "23                            28            0  \n",
       "24                            21            0  \n",
       "25                            22            0  \n",
       "26                            48            1  \n",
       "27                            16            0  \n",
       "\n",
       "[28 rows x 27 columns]"
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.76900e+00, 1.06440e+00, 1.35600e-01, 2.45000e-01, 2.10000e-01,\n",
       "        5.34700e-01, 6.53000e-02, 1.40000e-01, 1.25400e-01, 5.28100e-01,\n",
       "        7.19000e-02, 1.48600e-01, 1.20500e-01, 5.42200e-01, 5.78000e-02,\n",
       "        1.29200e-01, 1.26000e-01, 1.60000e-01, 1.50000e-02, 7.50000e-03,\n",
       "        7.50000e-03, 3.38671e+01, 2.71121e+01, 6.75490e+00, 6.58280e+00,\n",
       "        1.50000e+01, 0.00000e+00],\n",
       "       [1.74630e+00, 1.07070e+00, 7.00000e-04, 3.91700e-01, 2.00000e-01,\n",
       "        5.35300e-01, 3.00000e-04, 2.00800e-01, 1.10200e-01, 5.40100e-01,\n",
       "        1.00000e-04, 2.06400e-01, 1.17000e-01, 5.30500e-01, 5.00000e-04,\n",
       "        1.94900e-01, 1.02600e-01, 1.94100e-01, 1.91000e-02, 9.60000e-03,\n",
       "        9.60000e-03, 2.98176e+01, 2.68024e+01, 3.01530e+00, 9.38310e+00,\n",
       "        8.00000e+00, 0.00000e+00],\n",
       "       [1.73940e+00, 9.80000e-01, 2.00000e-02, 2.71800e-01, 1.80000e-01,\n",
       "        4.90000e-01, 1.00000e-02, 1.42300e-01, 9.78000e-02, 5.10000e-01,\n",
       "        1.00000e-02, 1.55400e-01, 1.00000e-01, 4.70000e-01, 3.00000e-02,\n",
       "        1.24700e-01, 9.29000e-02, 1.41400e-01, 3.36000e-02, 1.68000e-02,\n",
       "        1.68000e-02, 2.80941e+01, 2.51114e+01, 2.98270e+00, 6.58020e+00,\n",
       "        1.80000e+01, 0.00000e+00],\n",
       "       [1.74480e+00, 9.97300e-01, 2.02700e-01, 3.14400e-01, 2.80000e-01,\n",
       "        4.99600e-01, 1.00400e-01, 1.67100e-01, 1.47200e-01, 5.23200e-01,\n",
       "        7.68000e-02, 1.57300e-01, 1.41400e-01, 4.73700e-01, 1.26300e-01,\n",
       "        1.73700e-01, 1.48800e-01, 1.57200e-01, 1.78000e-02, 8.90000e-03,\n",
       "        8.90000e-03, 3.38671e+01, 2.54250e+01, 8.44200e+00, 7.93300e+00,\n",
       "        2.10000e+01, 0.00000e+00],\n",
       "       [1.75320e+00, 9.23700e-01, 2.76300e-01, 3.20300e-01, 3.20000e-01,\n",
       "        4.50000e-01, 1.50000e-01, 1.71000e-01, 1.69300e-01, 4.58000e-01,\n",
       "        1.42000e-01, 1.69600e-01, 1.67600e-01, 4.41200e-01, 1.58800e-01,\n",
       "        1.72100e-01, 1.70700e-01, 1.73100e-01, 1.90000e-03, 9.00000e-04,\n",
       "        9.00000e-04, 3.38671e+01, 2.31380e+01, 1.07291e+01, 8.23330e+00,\n",
       "        2.30000e+01, 0.00000e+00],\n",
       "       [1.72370e+00, 8.78900e-01, 1.21100e-01, 1.91600e-01, 1.30000e-01,\n",
       "        4.39400e-01, 6.06000e-02, 1.05400e-01, 7.81000e-02, 4.24000e-01,\n",
       "        7.60000e-02, 1.31700e-01, 9.22000e-02, 4.54900e-01, 4.51000e-02,\n",
       "        6.65000e-02, 4.66000e-02, 1.75800e-01, 8.00000e-04, 4.00000e-04,\n",
       "        4.00000e-04, 2.80941e+01, 2.29306e+01, 5.16350e+00, 5.10380e+00,\n",
       "        1.20000e+01, 0.00000e+00],\n",
       "       [1.73170e+00, 7.44900e-01, 5.51000e-02, 2.05500e-01, 1.40000e-01,\n",
       "        3.79100e-01, 2.09000e-02, 1.04500e-01, 7.37000e-02, 4.07900e-01,\n",
       "        7.90000e-03, 1.10300e-01, 6.81000e-02, 3.43100e-01, 5.69000e-02,\n",
       "        8.37000e-02, 7.83000e-02, 1.99000e-01, 2.40000e-02, 1.20000e-02,\n",
       "        1.20000e-02, 2.23930e+01, 2.00455e+01, 2.34760e+00, 5.21660e+00,\n",
       "        9.00000e+00, 0.00000e+00],\n",
       "       [1.68710e+00, 7.64800e-01, 3.52000e-02, 2.45000e-02, 2.00000e-02,\n",
       "        3.79100e-01, 2.09000e-02, 1.48000e-02, 1.37000e-02, 3.80100e-01,\n",
       "        1.99000e-02, 1.65000e-02, 1.47000e-02, 3.77800e-01, 2.22000e-02,\n",
       "        1.22000e-02, 1.22000e-02, 1.30900e-01, 4.41000e-02, 2.21000e-02,\n",
       "        2.21000e-02, 2.23930e+01, 2.02036e+01, 2.18940e+00, 7.26900e-01,\n",
       "        7.00000e+00, 0.00000e+00],\n",
       "       [1.72920e+00, 6.88700e-01, 1.11300e-01, 1.71000e-01, 1.60000e-01,\n",
       "        3.44300e-01, 5.57000e-02, 8.75000e-02, 7.63000e-02, 3.38600e-01,\n",
       "        6.14000e-02, 8.49000e-02, 7.30000e-02, 3.50100e-01, 4.99000e-02,\n",
       "        8.97000e-02, 7.92000e-02, 1.80000e-01, 5.00000e-03, 2.50000e-03,\n",
       "        2.50000e-03, 2.23930e+01, 1.83793e+01, 4.01370e+00, 4.46450e+00,\n",
       "        1.80000e+01, 0.00000e+00],\n",
       "       [1.72440e+00, 7.03000e-01, 9.70000e-02, 1.43400e-01, 1.40000e-01,\n",
       "        3.51500e-01, 4.85000e-02, 7.30000e-02, 6.54000e-02, 3.50300e-01,\n",
       "        4.97000e-02, 7.11000e-02, 6.71000e-02, 3.52700e-01, 4.73000e-02,\n",
       "        7.49000e-02, 6.34000e-02, 2.09100e-01, 2.41000e-02, 1.20000e-02,\n",
       "        1.20000e-02, 2.23930e+01, 1.87675e+01, 3.62550e+00, 3.71230e+00,\n",
       "        2.00000e+01, 0.00000e+00],\n",
       "       [1.72560e+00, 7.17400e-01, 8.26000e-02, 1.59800e-01, 1.30000e-01,\n",
       "        3.54900e-01, 4.51000e-02, 8.67000e-02, 6.70000e-02, 3.48700e-01,\n",
       "        5.13000e-02, 9.09000e-02, 6.68000e-02, 3.61500e-01, 3.85000e-02,\n",
       "        8.15000e-02, 6.60000e-02, 1.84700e-01, 9.70000e-03, 4.80000e-03,\n",
       "        4.80000e-03, 2.23930e+01, 1.89055e+01, 3.48750e+00, 4.36880e+00,\n",
       "        3.30000e+01, 0.00000e+00],\n",
       "       [1.71750e+00, 7.88600e-01, 1.14000e-02, 1.11600e-01, 9.00000e-02,\n",
       "        3.97600e-01, 2.40000e-03, 6.80000e-02, 4.96000e-02, 3.99100e-01,\n",
       "        9.00000e-04, 7.78000e-02, 5.06000e-02, 3.96100e-01, 3.90000e-03,\n",
       "        5.56000e-02, 4.48000e-02, 2.07000e-01, 1.02000e-01, 5.10000e-02,\n",
       "        5.10000e-02, 2.23930e+01, 2.10406e+01, 1.35240e+00, 3.39470e+00,\n",
       "        3.10000e+01, 0.00000e+00],\n",
       "       [1.71620e+00, 7.77000e-01, 2.30000e-02, 1.13600e-01, 8.00000e-02,\n",
       "        3.88500e-01, 1.15000e-02, 6.68000e-02, 4.96000e-02, 3.93900e-01,\n",
       "        6.10000e-03, 6.94000e-02, 5.45000e-02, 3.83200e-01, 1.68000e-02,\n",
       "        6.37000e-02, 4.39000e-02, 2.26500e-01, 1.21500e-01, 6.08000e-02,\n",
       "        6.08000e-02, 2.23930e+01, 2.06005e+01, 1.79250e+00, 3.33500e+00,\n",
       "        3.20000e+01, 0.00000e+00],\n",
       "       [1.73380e+00, 7.75500e-01, 2.45000e-02, 1.02900e-01, 9.00000e-02,\n",
       "        3.83000e-01, 1.70000e-02, 6.14000e-02, 4.86000e-02, 3.78800e-01,\n",
       "        2.12000e-02, 6.60000e-02, 5.07000e-02, 3.87500e-01, 1.25000e-02,\n",
       "        5.58000e-02, 4.53000e-02, 2.05900e-01, 3.09000e-02, 1.55000e-02,\n",
       "        1.55000e-02, 2.23930e+01, 2.03442e+01, 2.04880e+00, 3.09070e+00,\n",
       "        3.10000e+01, 0.00000e+00],\n",
       "       [1.42500e+00, 7.92400e-01, 7.60000e-03, 1.46200e-01, 8.00000e-02,\n",
       "        3.99600e-01, 4.00000e-04, 9.10000e-02, 5.43000e-02, 4.32800e-01,\n",
       "        3.28000e-02, 9.47000e-02, 4.84000e-02, 3.63500e-01, 3.65000e-02,\n",
       "        7.09000e-02, 5.58000e-02, 2.34100e-01, 4.91000e-02, 2.45000e-02,\n",
       "        2.45000e-02, 2.65806e+01, 2.44826e+01, 2.09810e+00, 5.09580e+00,\n",
       "        2.30000e+01, 1.00000e+00],\n",
       "       [1.70910e+00, 1.01330e+00, 7.33000e-02, 2.11900e-01, 1.10000e-01,\n",
       "        5.06700e-01, 3.67000e-02, 1.16700e-01, 5.43000e-02, 4.93300e-01,\n",
       "        2.33000e-02, 1.20200e-01, 5.16000e-02, 5.20000e-01, 5.00000e-02,\n",
       "        1.11500e-01, 5.68000e-02, 2.41300e-01, 5.63000e-02, 2.81000e-02,\n",
       "        2.81000e-02, 2.63770e+01, 2.59638e+01, 4.13200e-01, 5.34780e+00,\n",
       "        4.80000e+01, 0.00000e+00],\n",
       "       [1.68730e+00, 7.72700e-01, 1.37300e-01, 6.87000e-02, 5.00000e-02,\n",
       "        3.83600e-01, 7.14000e-02, 5.88000e-02, 4.70000e-02, 3.77400e-01,\n",
       "        1.72600e-01, 7.47000e-02, 7.47000e-02, 3.90500e-01, 3.05000e-02,\n",
       "        3.23000e-02, 2.34000e-02, 1.43200e-01, 4.18000e-02, 2.09000e-02,\n",
       "        2.09000e-02, 2.01291e+01, 2.03752e+01, 2.46100e-01, 2.84050e+00,\n",
       "        2.30000e+01, 0.00000e+00],\n",
       "       [1.69140e+00, 7.63400e-01, 1.46600e-01, 1.17000e-01, 7.00000e-02,\n",
       "        3.81700e-01, 7.33000e-02, 7.81000e-02, 5.04000e-02, 3.95500e-01,\n",
       "        1.54500e-01, 1.02900e-01, 5.43000e-02, 3.68000e-01, 8.00000e-03,\n",
       "        3.52000e-02, 2.16000e-02, 1.40700e-01, 3.43000e-02, 1.71000e-02,\n",
       "        1.71000e-02, 2.01291e+01, 2.02362e+01, 1.07100e-01, 3.57880e+00,\n",
       "        2.60000e+01, 0.00000e+00],\n",
       "       [1.67350e+00, 7.47900e-01, 5.21000e-02, 4.89000e-02, 3.00000e-02,\n",
       "        3.75600e-01, 2.44000e-02, 4.89000e-02, 3.41000e-02, 3.58500e-01,\n",
       "        4.15000e-02, 3.36000e-02, 2.99000e-02, 3.93800e-01, 6.20000e-03,\n",
       "        5.57000e-02, 3.81000e-02, 1.60500e-01, 2.45000e-02, 1.23000e-02,\n",
       "        1.23000e-02, 2.23930e+01, 1.99958e+01, 2.39720e+00, 2.35650e+00,\n",
       "        2.90000e+01, 0.00000e+00],\n",
       "       [1.60790e+00, 7.30600e-01, 6.94000e-02, 4.54000e-02, 4.00000e-02,\n",
       "        3.65300e-01, 3.47000e-02, 4.46000e-02, 3.48000e-02, 3.62800e-01,\n",
       "        3.72000e-02, 5.42000e-02, 3.89000e-02, 3.67800e-01, 3.22000e-02,\n",
       "        3.20000e-02, 2.76000e-02, 1.80500e-01, 4.50000e-03, 2.30000e-03,\n",
       "        2.30000e-03, 2.23930e+01, 1.94980e+01, 2.89500e+00, 2.18380e+00,\n",
       "        3.00000e+01, 0.00000e+00],\n",
       "       [1.69640e+00, 7.71100e-01, 2.89000e-02, 8.78000e-02, 6.00000e-02,\n",
       "        3.85600e-01, 1.44000e-02, 5.30000e-02, 3.67000e-02, 3.91300e-01,\n",
       "        8.70000e-03, 3.87000e-02, 2.53000e-02, 3.79800e-01, 2.02000e-02,\n",
       "        6.37000e-02, 4.29000e-02, 1.60500e-01, 2.45000e-02, 1.22000e-02,\n",
       "        1.22000e-02, 2.23930e+01, 2.04787e+01, 1.91440e+00, 2.58410e+00,\n",
       "        2.20000e+01, 0.00000e+00],\n",
       "       [1.71790e+00, 8.04800e-01, 4.80000e-03, 1.65200e-01, 8.00000e-02,\n",
       "        4.02400e-01, 2.40000e-03, 1.23800e-01, 9.11000e-02, 3.77800e-01,\n",
       "        2.22000e-02, 5.64000e-02, 3.59000e-02, 4.27000e-01, 2.70000e-02,\n",
       "        1.62000e-01, 1.13300e-01, 1.48200e-01, 3.68000e-02, 1.84000e-02,\n",
       "        1.84000e-02, 2.23930e+01, 2.10872e+01, 1.30580e+00, 5.49740e+00,\n",
       "        2.20000e+01, 0.00000e+00],\n",
       "       [1.71530e+00, 8.04000e-01, 4.00000e-03, 6.27000e-02, 4.00000e-02,\n",
       "        4.01600e-01, 1.60000e-03, 3.19000e-02, 2.00000e-02, 4.00700e-01,\n",
       "        7.00000e-04, 3.17000e-02, 1.98000e-02, 4.02600e-01, 2.60000e-03,\n",
       "        3.22000e-02, 2.02000e-02, 8.33000e-02, 1.01700e-01, 5.08000e-02,\n",
       "        5.08000e-02, 2.23930e+01, 2.12856e+01, 1.10740e+00, 1.53330e+00,\n",
       "        2.50000e+01, 0.00000e+00],\n",
       "       [1.75610e+00, 6.93100e-01, 7.69000e-02, 1.13300e-01, 1.10000e-01,\n",
       "        3.46600e-01, 3.84000e-02, 6.42000e-02, 5.49000e-02, 3.34500e-01,\n",
       "        3.55000e-02, 5.99000e-02, 5.46000e-02, 3.58600e-01, 4.14000e-02,\n",
       "        6.61000e-02, 5.77000e-02, 2.17800e-01, 3.28000e-02, 1.64000e-02,\n",
       "        1.64000e-02, 2.26155e+01, 1.87064e+01, 3.90910e+00, 3.28500e+00,\n",
       "        2.80000e+01, 0.00000e+00],\n",
       "       [1.68450e+00, 7.75600e-01, 5.60000e-03, 4.75000e-02, 2.00000e-02,\n",
       "        3.79200e-01, 5.80000e-03, 5.00000e-02, 3.81000e-02, 3.74500e-01,\n",
       "        4.50000e-03, 6.33000e-02, 4.33000e-02, 3.84400e-01, 1.56000e-02,\n",
       "        2.79000e-02, 2.24000e-02, 1.04600e-01, 8.04000e-02, 4.02000e-02,\n",
       "        4.02000e-02, 2.26155e+01, 2.03555e+01, 2.26000e+00, 2.53110e+00,\n",
       "        2.10000e+01, 0.00000e+00],\n",
       "       [1.70690e+00, 7.98200e-01, 1.80000e-03, 5.18000e-02, 3.00000e-02,\n",
       "        3.99100e-01, 9.00000e-04, 3.14000e-02, 2.04000e-02, 4.00000e-01,\n",
       "        0.00000e+00, 3.20000e-02, 2.28000e-02, 3.98200e-01, 1.80000e-03,\n",
       "        3.08000e-02, 1.76000e-02, 8.49000e-02, 1.00100e-01, 5.00000e-02,\n",
       "        5.00000e-02, 2.26155e+01, 2.13530e+01, 1.26250e+00, 1.53600e+00,\n",
       "        2.20000e+01, 0.00000e+00],\n",
       "       [1.69620e+00, 7.98500e-01, 1.50000e-03, 6.83000e-02, 5.00000e-02,\n",
       "        3.99200e-01, 8.00000e-04, 5.21000e-02, 3.03000e-02, 3.99800e-01,\n",
       "        2.00000e-04, 4.83000e-02, 2.94000e-02, 3.98700e-01, 1.30000e-03,\n",
       "        5.56000e-02, 3.06000e-02, 1.81300e-01, 3.70000e-03, 1.90000e-03,\n",
       "        1.90000e-03, 2.23930e+01, 2.11445e+01, 1.24860e+00, 2.51830e+00,\n",
       "        4.80000e+01, 1.00000e+00],\n",
       "       [1.43120e+00, 7.53900e-01, 4.61000e-02, 6.28000e-02, 6.00000e-02,\n",
       "        3.76900e-01, 2.31000e-02, 5.35000e-02, 3.63000e-02, 3.63000e-01,\n",
       "        3.70000e-02, 4.85000e-02, 4.07000e-02, 3.90900e-01, 9.10000e-03,\n",
       "        5.46000e-02, 3.12000e-02, 1.74500e-01, 1.05000e-02, 5.30000e-03,\n",
       "        5.30000e-03, 2.65806e+01, 2.33593e+01, 3.22140e+00, 2.98070e+00,\n",
       "        1.60000e+01, 0.00000e+00]])"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset[:,0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.76900e+00, 1.06440e+00, 1.35600e-01, 2.45000e-01, 2.10000e-01,\n",
       "        5.34700e-01, 6.53000e-02, 1.40000e-01, 1.25400e-01, 5.28100e-01,\n",
       "        7.19000e-02, 1.48600e-01, 1.20500e-01, 5.42200e-01, 5.78000e-02,\n",
       "        1.29200e-01, 1.26000e-01, 1.60000e-01, 1.50000e-02, 7.50000e-03,\n",
       "        7.50000e-03, 3.38671e+01, 2.71121e+01, 6.75490e+00, 6.58280e+00],\n",
       "       [1.74630e+00, 1.07070e+00, 7.00000e-04, 3.91700e-01, 2.00000e-01,\n",
       "        5.35300e-01, 3.00000e-04, 2.00800e-01, 1.10200e-01, 5.40100e-01,\n",
       "        1.00000e-04, 2.06400e-01, 1.17000e-01, 5.30500e-01, 5.00000e-04,\n",
       "        1.94900e-01, 1.02600e-01, 1.94100e-01, 1.91000e-02, 9.60000e-03,\n",
       "        9.60000e-03, 2.98176e+01, 2.68024e+01, 3.01530e+00, 9.38310e+00],\n",
       "       [1.73940e+00, 9.80000e-01, 2.00000e-02, 2.71800e-01, 1.80000e-01,\n",
       "        4.90000e-01, 1.00000e-02, 1.42300e-01, 9.78000e-02, 5.10000e-01,\n",
       "        1.00000e-02, 1.55400e-01, 1.00000e-01, 4.70000e-01, 3.00000e-02,\n",
       "        1.24700e-01, 9.29000e-02, 1.41400e-01, 3.36000e-02, 1.68000e-02,\n",
       "        1.68000e-02, 2.80941e+01, 2.51114e+01, 2.98270e+00, 6.58020e+00],\n",
       "       [1.74480e+00, 9.97300e-01, 2.02700e-01, 3.14400e-01, 2.80000e-01,\n",
       "        4.99600e-01, 1.00400e-01, 1.67100e-01, 1.47200e-01, 5.23200e-01,\n",
       "        7.68000e-02, 1.57300e-01, 1.41400e-01, 4.73700e-01, 1.26300e-01,\n",
       "        1.73700e-01, 1.48800e-01, 1.57200e-01, 1.78000e-02, 8.90000e-03,\n",
       "        8.90000e-03, 3.38671e+01, 2.54250e+01, 8.44200e+00, 7.93300e+00],\n",
       "       [1.75320e+00, 9.23700e-01, 2.76300e-01, 3.20300e-01, 3.20000e-01,\n",
       "        4.50000e-01, 1.50000e-01, 1.71000e-01, 1.69300e-01, 4.58000e-01,\n",
       "        1.42000e-01, 1.69600e-01, 1.67600e-01, 4.41200e-01, 1.58800e-01,\n",
       "        1.72100e-01, 1.70700e-01, 1.73100e-01, 1.90000e-03, 9.00000e-04,\n",
       "        9.00000e-04, 3.38671e+01, 2.31380e+01, 1.07291e+01, 8.23330e+00],\n",
       "       [1.72370e+00, 8.78900e-01, 1.21100e-01, 1.91600e-01, 1.30000e-01,\n",
       "        4.39400e-01, 6.06000e-02, 1.05400e-01, 7.81000e-02, 4.24000e-01,\n",
       "        7.60000e-02, 1.31700e-01, 9.22000e-02, 4.54900e-01, 4.51000e-02,\n",
       "        6.65000e-02, 4.66000e-02, 1.75800e-01, 8.00000e-04, 4.00000e-04,\n",
       "        4.00000e-04, 2.80941e+01, 2.29306e+01, 5.16350e+00, 5.10380e+00],\n",
       "       [1.73170e+00, 7.44900e-01, 5.51000e-02, 2.05500e-01, 1.40000e-01,\n",
       "        3.79100e-01, 2.09000e-02, 1.04500e-01, 7.37000e-02, 4.07900e-01,\n",
       "        7.90000e-03, 1.10300e-01, 6.81000e-02, 3.43100e-01, 5.69000e-02,\n",
       "        8.37000e-02, 7.83000e-02, 1.99000e-01, 2.40000e-02, 1.20000e-02,\n",
       "        1.20000e-02, 2.23930e+01, 2.00455e+01, 2.34760e+00, 5.21660e+00],\n",
       "       [1.68710e+00, 7.64800e-01, 3.52000e-02, 2.45000e-02, 2.00000e-02,\n",
       "        3.79100e-01, 2.09000e-02, 1.48000e-02, 1.37000e-02, 3.80100e-01,\n",
       "        1.99000e-02, 1.65000e-02, 1.47000e-02, 3.77800e-01, 2.22000e-02,\n",
       "        1.22000e-02, 1.22000e-02, 1.30900e-01, 4.41000e-02, 2.21000e-02,\n",
       "        2.21000e-02, 2.23930e+01, 2.02036e+01, 2.18940e+00, 7.26900e-01],\n",
       "       [1.72920e+00, 6.88700e-01, 1.11300e-01, 1.71000e-01, 1.60000e-01,\n",
       "        3.44300e-01, 5.57000e-02, 8.75000e-02, 7.63000e-02, 3.38600e-01,\n",
       "        6.14000e-02, 8.49000e-02, 7.30000e-02, 3.50100e-01, 4.99000e-02,\n",
       "        8.97000e-02, 7.92000e-02, 1.80000e-01, 5.00000e-03, 2.50000e-03,\n",
       "        2.50000e-03, 2.23930e+01, 1.83793e+01, 4.01370e+00, 4.46450e+00],\n",
       "       [1.72440e+00, 7.03000e-01, 9.70000e-02, 1.43400e-01, 1.40000e-01,\n",
       "        3.51500e-01, 4.85000e-02, 7.30000e-02, 6.54000e-02, 3.50300e-01,\n",
       "        4.97000e-02, 7.11000e-02, 6.71000e-02, 3.52700e-01, 4.73000e-02,\n",
       "        7.49000e-02, 6.34000e-02, 2.09100e-01, 2.41000e-02, 1.20000e-02,\n",
       "        1.20000e-02, 2.23930e+01, 1.87675e+01, 3.62550e+00, 3.71230e+00],\n",
       "       [1.72560e+00, 7.17400e-01, 8.26000e-02, 1.59800e-01, 1.30000e-01,\n",
       "        3.54900e-01, 4.51000e-02, 8.67000e-02, 6.70000e-02, 3.48700e-01,\n",
       "        5.13000e-02, 9.09000e-02, 6.68000e-02, 3.61500e-01, 3.85000e-02,\n",
       "        8.15000e-02, 6.60000e-02, 1.84700e-01, 9.70000e-03, 4.80000e-03,\n",
       "        4.80000e-03, 2.23930e+01, 1.89055e+01, 3.48750e+00, 4.36880e+00],\n",
       "       [1.71750e+00, 7.88600e-01, 1.14000e-02, 1.11600e-01, 9.00000e-02,\n",
       "        3.97600e-01, 2.40000e-03, 6.80000e-02, 4.96000e-02, 3.99100e-01,\n",
       "        9.00000e-04, 7.78000e-02, 5.06000e-02, 3.96100e-01, 3.90000e-03,\n",
       "        5.56000e-02, 4.48000e-02, 2.07000e-01, 1.02000e-01, 5.10000e-02,\n",
       "        5.10000e-02, 2.23930e+01, 2.10406e+01, 1.35240e+00, 3.39470e+00],\n",
       "       [1.71620e+00, 7.77000e-01, 2.30000e-02, 1.13600e-01, 8.00000e-02,\n",
       "        3.88500e-01, 1.15000e-02, 6.68000e-02, 4.96000e-02, 3.93900e-01,\n",
       "        6.10000e-03, 6.94000e-02, 5.45000e-02, 3.83200e-01, 1.68000e-02,\n",
       "        6.37000e-02, 4.39000e-02, 2.26500e-01, 1.21500e-01, 6.08000e-02,\n",
       "        6.08000e-02, 2.23930e+01, 2.06005e+01, 1.79250e+00, 3.33500e+00],\n",
       "       [1.73380e+00, 7.75500e-01, 2.45000e-02, 1.02900e-01, 9.00000e-02,\n",
       "        3.83000e-01, 1.70000e-02, 6.14000e-02, 4.86000e-02, 3.78800e-01,\n",
       "        2.12000e-02, 6.60000e-02, 5.07000e-02, 3.87500e-01, 1.25000e-02,\n",
       "        5.58000e-02, 4.53000e-02, 2.05900e-01, 3.09000e-02, 1.55000e-02,\n",
       "        1.55000e-02, 2.23930e+01, 2.03442e+01, 2.04880e+00, 3.09070e+00],\n",
       "       [1.42500e+00, 7.92400e-01, 7.60000e-03, 1.46200e-01, 8.00000e-02,\n",
       "        3.99600e-01, 4.00000e-04, 9.10000e-02, 5.43000e-02, 4.32800e-01,\n",
       "        3.28000e-02, 9.47000e-02, 4.84000e-02, 3.63500e-01, 3.65000e-02,\n",
       "        7.09000e-02, 5.58000e-02, 2.34100e-01, 4.91000e-02, 2.45000e-02,\n",
       "        2.45000e-02, 2.65806e+01, 2.44826e+01, 2.09810e+00, 5.09580e+00],\n",
       "       [1.70910e+00, 1.01330e+00, 7.33000e-02, 2.11900e-01, 1.10000e-01,\n",
       "        5.06700e-01, 3.67000e-02, 1.16700e-01, 5.43000e-02, 4.93300e-01,\n",
       "        2.33000e-02, 1.20200e-01, 5.16000e-02, 5.20000e-01, 5.00000e-02,\n",
       "        1.11500e-01, 5.68000e-02, 2.41300e-01, 5.63000e-02, 2.81000e-02,\n",
       "        2.81000e-02, 2.63770e+01, 2.59638e+01, 4.13200e-01, 5.34780e+00],\n",
       "       [1.68730e+00, 7.72700e-01, 1.37300e-01, 6.87000e-02, 5.00000e-02,\n",
       "        3.83600e-01, 7.14000e-02, 5.88000e-02, 4.70000e-02, 3.77400e-01,\n",
       "        1.72600e-01, 7.47000e-02, 7.47000e-02, 3.90500e-01, 3.05000e-02,\n",
       "        3.23000e-02, 2.34000e-02, 1.43200e-01, 4.18000e-02, 2.09000e-02,\n",
       "        2.09000e-02, 2.01291e+01, 2.03752e+01, 2.46100e-01, 2.84050e+00],\n",
       "       [1.69140e+00, 7.63400e-01, 1.46600e-01, 1.17000e-01, 7.00000e-02,\n",
       "        3.81700e-01, 7.33000e-02, 7.81000e-02, 5.04000e-02, 3.95500e-01,\n",
       "        1.54500e-01, 1.02900e-01, 5.43000e-02, 3.68000e-01, 8.00000e-03,\n",
       "        3.52000e-02, 2.16000e-02, 1.40700e-01, 3.43000e-02, 1.71000e-02,\n",
       "        1.71000e-02, 2.01291e+01, 2.02362e+01, 1.07100e-01, 3.57880e+00],\n",
       "       [1.67350e+00, 7.47900e-01, 5.21000e-02, 4.89000e-02, 3.00000e-02,\n",
       "        3.75600e-01, 2.44000e-02, 4.89000e-02, 3.41000e-02, 3.58500e-01,\n",
       "        4.15000e-02, 3.36000e-02, 2.99000e-02, 3.93800e-01, 6.20000e-03,\n",
       "        5.57000e-02, 3.81000e-02, 1.60500e-01, 2.45000e-02, 1.23000e-02,\n",
       "        1.23000e-02, 2.23930e+01, 1.99958e+01, 2.39720e+00, 2.35650e+00],\n",
       "       [1.60790e+00, 7.30600e-01, 6.94000e-02, 4.54000e-02, 4.00000e-02,\n",
       "        3.65300e-01, 3.47000e-02, 4.46000e-02, 3.48000e-02, 3.62800e-01,\n",
       "        3.72000e-02, 5.42000e-02, 3.89000e-02, 3.67800e-01, 3.22000e-02,\n",
       "        3.20000e-02, 2.76000e-02, 1.80500e-01, 4.50000e-03, 2.30000e-03,\n",
       "        2.30000e-03, 2.23930e+01, 1.94980e+01, 2.89500e+00, 2.18380e+00],\n",
       "       [1.69640e+00, 7.71100e-01, 2.89000e-02, 8.78000e-02, 6.00000e-02,\n",
       "        3.85600e-01, 1.44000e-02, 5.30000e-02, 3.67000e-02, 3.91300e-01,\n",
       "        8.70000e-03, 3.87000e-02, 2.53000e-02, 3.79800e-01, 2.02000e-02,\n",
       "        6.37000e-02, 4.29000e-02, 1.60500e-01, 2.45000e-02, 1.22000e-02,\n",
       "        1.22000e-02, 2.23930e+01, 2.04787e+01, 1.91440e+00, 2.58410e+00],\n",
       "       [1.71790e+00, 8.04800e-01, 4.80000e-03, 1.65200e-01, 8.00000e-02,\n",
       "        4.02400e-01, 2.40000e-03, 1.23800e-01, 9.11000e-02, 3.77800e-01,\n",
       "        2.22000e-02, 5.64000e-02, 3.59000e-02, 4.27000e-01, 2.70000e-02,\n",
       "        1.62000e-01, 1.13300e-01, 1.48200e-01, 3.68000e-02, 1.84000e-02,\n",
       "        1.84000e-02, 2.23930e+01, 2.10872e+01, 1.30580e+00, 5.49740e+00],\n",
       "       [1.71530e+00, 8.04000e-01, 4.00000e-03, 6.27000e-02, 4.00000e-02,\n",
       "        4.01600e-01, 1.60000e-03, 3.19000e-02, 2.00000e-02, 4.00700e-01,\n",
       "        7.00000e-04, 3.17000e-02, 1.98000e-02, 4.02600e-01, 2.60000e-03,\n",
       "        3.22000e-02, 2.02000e-02, 8.33000e-02, 1.01700e-01, 5.08000e-02,\n",
       "        5.08000e-02, 2.23930e+01, 2.12856e+01, 1.10740e+00, 1.53330e+00],\n",
       "       [1.75610e+00, 6.93100e-01, 7.69000e-02, 1.13300e-01, 1.10000e-01,\n",
       "        3.46600e-01, 3.84000e-02, 6.42000e-02, 5.49000e-02, 3.34500e-01,\n",
       "        3.55000e-02, 5.99000e-02, 5.46000e-02, 3.58600e-01, 4.14000e-02,\n",
       "        6.61000e-02, 5.77000e-02, 2.17800e-01, 3.28000e-02, 1.64000e-02,\n",
       "        1.64000e-02, 2.26155e+01, 1.87064e+01, 3.90910e+00, 3.28500e+00],\n",
       "       [1.68450e+00, 7.75600e-01, 5.60000e-03, 4.75000e-02, 2.00000e-02,\n",
       "        3.79200e-01, 5.80000e-03, 5.00000e-02, 3.81000e-02, 3.74500e-01,\n",
       "        4.50000e-03, 6.33000e-02, 4.33000e-02, 3.84400e-01, 1.56000e-02,\n",
       "        2.79000e-02, 2.24000e-02, 1.04600e-01, 8.04000e-02, 4.02000e-02,\n",
       "        4.02000e-02, 2.26155e+01, 2.03555e+01, 2.26000e+00, 2.53110e+00],\n",
       "       [1.70690e+00, 7.98200e-01, 1.80000e-03, 5.18000e-02, 3.00000e-02,\n",
       "        3.99100e-01, 9.00000e-04, 3.14000e-02, 2.04000e-02, 4.00000e-01,\n",
       "        0.00000e+00, 3.20000e-02, 2.28000e-02, 3.98200e-01, 1.80000e-03,\n",
       "        3.08000e-02, 1.76000e-02, 8.49000e-02, 1.00100e-01, 5.00000e-02,\n",
       "        5.00000e-02, 2.26155e+01, 2.13530e+01, 1.26250e+00, 1.53600e+00],\n",
       "       [1.69620e+00, 7.98500e-01, 1.50000e-03, 6.83000e-02, 5.00000e-02,\n",
       "        3.99200e-01, 8.00000e-04, 5.21000e-02, 3.03000e-02, 3.99800e-01,\n",
       "        2.00000e-04, 4.83000e-02, 2.94000e-02, 3.98700e-01, 1.30000e-03,\n",
       "        5.56000e-02, 3.06000e-02, 1.81300e-01, 3.70000e-03, 1.90000e-03,\n",
       "        1.90000e-03, 2.23930e+01, 2.11445e+01, 1.24860e+00, 2.51830e+00],\n",
       "       [1.43120e+00, 7.53900e-01, 4.61000e-02, 6.28000e-02, 6.00000e-02,\n",
       "        3.76900e-01, 2.31000e-02, 5.35000e-02, 3.63000e-02, 3.63000e-01,\n",
       "        3.70000e-02, 4.85000e-02, 4.07000e-02, 3.90900e-01, 9.10000e-03,\n",
       "        5.46000e-02, 3.12000e-02, 1.74500e-01, 1.05000e-02, 5.30000e-03,\n",
       "        5.30000e-03, 2.65806e+01, 2.33593e+01, 3.22140e+00, 2.98070e+00]])"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=dataset[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 25) (2,)\n",
      "(26, 25) (26,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu',  kernel_regularizer=regularizers.l2(0.01), input_shape=(25,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "#     Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "#     Dropout(0.3),\n",
    "# #     Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "#     Dropout(0.3),\n",
    "#   Dense(100, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples, validate on 26 samples\n",
      "Epoch 1/10000\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 6.8405e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 2/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4266e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 3/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5367e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 4/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5780e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 5/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7016e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 6/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7560e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 7/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6614e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 8/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6763e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 9/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8061e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 10/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.2279e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 11/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3955e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 12/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4199e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 13/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9055e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 14/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4172e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 15/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0185e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 16/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5757e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 17/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9342e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 18/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2353e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 19/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5281e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 20/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6680e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 21/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5765e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 22/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8423e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 23/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8668e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 24/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9843e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 25/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8366e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 26/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5397e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 27/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7870e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 28/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5988e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 29/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9588e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 30/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.1613e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 31/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2601e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 32/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3705e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 33/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7140e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 34/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4310e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 35/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1334e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 36/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4245e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 37/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.5466e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 38/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3547e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 39/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4704e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 40/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7410e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 41/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4479e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 42/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7803e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 43/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7166e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 44/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1969e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 45/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9285e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 46/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9618e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 47/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8105e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 48/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9988e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 49/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4602e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 50/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5926e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 51/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4483e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 52/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4710e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 53/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1227e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 54/10000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8827e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 55/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9533e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 56/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4027e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4657e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 58/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4271e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 59/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4271e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 60/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9366e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 61/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5149e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 62/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7462e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 63/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4747e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 64/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4762e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 65/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4666e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 66/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4322e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 67/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0046e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 68/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1682e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 69/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5258e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 70/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8030e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 71/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9857e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 72/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6784e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 73/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6805e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 74/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4559e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 75/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4335e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 76/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0454e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 77/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7199e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 78/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.9773e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 79/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8626e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 80/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4356e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 81/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6575e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 82/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9729e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 83/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.0665e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 84/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7858e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 85/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5727e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 86/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5965e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 87/10000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7210e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 88/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1685e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 89/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7744e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 90/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0169e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 91/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0795e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 92/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1078e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 93/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0113e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 94/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7752e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 95/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6896e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 96/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9650e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 97/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6729e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 98/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9273e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 99/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4501e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 100/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4858e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 101/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5621e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 102/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6199e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 103/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5737e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 104/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0939e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 105/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3550e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 106/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3696e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 107/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5163e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 108/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3771e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 109/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2406e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 110/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4464e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 111/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2293e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 112/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3039e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 113/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5777e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 114/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0724e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 115/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9391e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 116/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4938e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 117/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1299e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 118/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9012e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 119/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2612e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 120/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9122e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 121/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2325e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 122/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1120e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 123/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8706e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 124/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4229e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 125/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0271e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 126/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7417e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 127/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1703e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 128/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5811e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 129/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7899e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 130/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5477e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 131/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3682e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 132/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9971e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 133/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.5800e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 134/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7418e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 135/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4260e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 136/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.9841e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 137/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2076e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 138/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3985e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 139/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9175e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 140/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7185e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 141/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8570e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 142/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.2859e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 143/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3403e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 144/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6788e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 145/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3211e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 146/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6812e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 147/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5845e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 148/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6759e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 149/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4956e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 150/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5962e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 151/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8411e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 152/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1032e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 153/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7692e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 154/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8056e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 155/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7586e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 156/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4398e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 157/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1695e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 158/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4229e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 159/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9909e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 160/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9981e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 161/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9674e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 162/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8504e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 163/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0734e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 164/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1112e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 165/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7860e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 166/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7926e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 167/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0949e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 168/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4751e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3959e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 170/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1799e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 171/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.1636e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 172/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2324e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 173/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0162e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 174/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8947e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 175/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5140e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 176/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3053e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 177/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7291e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 178/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1847e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 179/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3335e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 180/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.2891e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 181/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1176e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 182/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8563e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 183/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.9728e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 184/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4158e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 185/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8210e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 186/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2029e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 187/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4406e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 188/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6349e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 189/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.5657e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 190/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8667e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 191/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8511e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 192/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0835e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 193/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2379e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 194/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3981e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 195/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.7604e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 196/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2379e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 197/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7789e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 198/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3119e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 199/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1150e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 200/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8544e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 201/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0178e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 202/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2343e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 203/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8393e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 204/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2487e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 205/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6906e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 206/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9311e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 207/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7370e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 208/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6308e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 209/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2664e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 210/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6519e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 211/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8505e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 212/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7059e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 213/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8142e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 214/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9377e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 215/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6687e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 216/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5453e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 217/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.3144e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 218/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6166e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 219/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.1574e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 220/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3278e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 221/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8134e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 222/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7775e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 223/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5526e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 224/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7348e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9734e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 226/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3131e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 227/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6482e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 228/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8356e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 229/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2508e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 230/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3122e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 231/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8021e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 232/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4270e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 233/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5387e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 234/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5712e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 235/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4557e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 236/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1567e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 237/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7764e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 238/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4211e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 239/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0663e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 240/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7969e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 241/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1570e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 242/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9444e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 243/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4042e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 244/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0144e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 245/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3439e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 246/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7182e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 247/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0830e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 248/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7716e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 249/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7780e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 250/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2377e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 251/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1673e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 252/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1394e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 253/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4782e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 254/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.7618e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 255/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1825e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 256/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8110e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 257/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.0816e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 258/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3345e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 259/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4020e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 260/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.0237e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 261/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3626e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 262/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2915e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 263/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6116e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 264/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8879e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 265/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1789e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 266/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7200e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 267/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6450e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 268/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7992e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 269/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4284e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 270/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3524e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 271/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2659e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 272/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5892e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 273/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2330e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 274/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4653e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 275/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5969e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 276/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.5162e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 277/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1549e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 278/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4139e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 279/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1268e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 280/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9973e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6829e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 282/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6196e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 283/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.2341e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 284/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3014e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 285/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.7431e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 286/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3072e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 287/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9192e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 288/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4825e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 289/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2440e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 290/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7987e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 291/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2427e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 292/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2924e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 293/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4395e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 294/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.3399e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 295/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4233e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 296/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5093e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 297/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5015e-04 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 298/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5467e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 299/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8907e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 300/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7198e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 301/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4413e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 302/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.5226e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 303/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2991e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 304/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2953e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 305/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4268e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 306/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9558e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 307/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9062e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 308/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6842e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 309/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6369e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 310/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9134e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 311/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4374e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 312/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8356e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 313/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8520e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 314/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6869e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 315/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7519e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 316/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1176e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 317/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1221e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 318/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5738e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 319/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5012e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 320/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3005e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 321/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2694e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 322/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4396e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 323/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6887e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 324/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4787e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 325/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5824e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 326/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3258e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 327/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8326e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 328/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8218e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 329/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.5733e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 330/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0443e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 331/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4837e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 332/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3259e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 333/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1687e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 334/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8640e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 335/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5947e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 336/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1175e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5827e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 338/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6532e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 339/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1667e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 340/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8553e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 341/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1210e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 342/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9523e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 343/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6063e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 344/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1436e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 345/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0319e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 346/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0642e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 347/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4736e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 348/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2419e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 349/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.2318e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 350/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2380e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 351/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0385e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 352/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9093e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 353/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9749e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 354/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9029e-05 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 355/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8833e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 356/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0249e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 357/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5419e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 358/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7947e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 359/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0474e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 360/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6686e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 361/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5490e-05 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 362/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7511e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 363/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0330e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 364/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9592e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 365/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5991e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 366/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3791e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 367/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9783e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 368/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1333e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 369/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8452e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 370/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3666e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 371/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8796e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 372/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0665e-05 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 373/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7656e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 374/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5777e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 375/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 376/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9151e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 377/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1053e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 378/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7246e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 379/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4557e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 380/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1162e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 381/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5260e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 382/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1417e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 383/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5118e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 384/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8013e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 385/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2162e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 386/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9562e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 387/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6566e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 388/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6532e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 389/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4088e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 390/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.1652e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 391/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8969e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 392/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3061e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8573e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 394/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.5342e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 395/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5818e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 396/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2399e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 397/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8609e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 398/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7988e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 399/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4924e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 400/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5562e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 401/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5532e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 402/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6377e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 403/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2572e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 404/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2297e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 405/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4784e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 406/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8608e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 407/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0984e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 408/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2843e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 409/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7073e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 410/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7158e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 411/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4857e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 412/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7518e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 413/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0490e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 414/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8879e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 415/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0047e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 416/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9024e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 417/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4104e-06 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 418/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7177e-05 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 419/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7397e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 420/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7460e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 421/10000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7386e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 422/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4681e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 423/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1432e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 424/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6774e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 425/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6153e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 426/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3907e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 427/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1196e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 428/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6777e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 429/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3758e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 430/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1344e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 431/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1088e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 432/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4775e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 433/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0802e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 434/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5925e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 435/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9764e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 436/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4225e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 437/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3646e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 438/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6534e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 439/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7222e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 440/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3067e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 441/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2063e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 442/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1534e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 443/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4433e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 444/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3338e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 445/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9410e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 446/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8582e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 447/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4047e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 448/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7665e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7173e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 450/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5282e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 451/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6836e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 452/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9504e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 453/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7132e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 454/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0802e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 455/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6057e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 456/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0780e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 457/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7806e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 458/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6573e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 459/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9203e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 460/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6800e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 461/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9995e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 462/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3189e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 463/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5666e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 464/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2652e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 465/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4954e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 466/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2505e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 467/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5988e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 468/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0350e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 469/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7335e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 470/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8292e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 471/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0934e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 472/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.5670e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 473/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4488e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 474/10000\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1372e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 475/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2910e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 476/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9386e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 477/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9453e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 478/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7394e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 479/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5767e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 480/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0907e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 481/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3007e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 482/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6364e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 483/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3515e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 484/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0258e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 485/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3563e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 486/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6584e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 487/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8128e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 488/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5871e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 489/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4869e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 490/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0513e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 491/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4361e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 492/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0603e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 493/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0771e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 494/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6458e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 495/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7822e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 496/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9144e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 497/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7231e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 498/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5218e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 499/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9212e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 500/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3832e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 501/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4800e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 502/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4338e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 503/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4854e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 504/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7079e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3733e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 506/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3575e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 507/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4986e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 508/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7758e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 509/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9693e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 510/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5533e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 511/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3087e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 512/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2292e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 513/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7831e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 514/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5414e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 515/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6003e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 516/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8028e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 517/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4020e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 518/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4207e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 519/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0359e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 520/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8650e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 521/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4611e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 522/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0226e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 523/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2914e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 524/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5724e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 525/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3430e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 526/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4412e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 527/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4333e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 528/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4046e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 529/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5811e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 530/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2062e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 531/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5458e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 532/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7239e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 533/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2429e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 534/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6942e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 535/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1869e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 536/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5698e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 537/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7548e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 538/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5196e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 539/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8261e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 540/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6069e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 541/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5432e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 542/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5446e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 543/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2701e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 544/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5949e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 545/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1224e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 546/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2266e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 547/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0869e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 548/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9047e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 549/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4166e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 550/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0046e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 551/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5910e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 552/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.2041e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 553/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4211e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 554/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2000e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 555/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1958e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 556/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1437e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 557/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.2854e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 558/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0451e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 559/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6345e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 560/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3708e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4973e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 562/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1827e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 563/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9213e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 564/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5199e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 565/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6451e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 566/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5214e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 567/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0682e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 568/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2130e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 569/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7277e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 570/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6406e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 571/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8106e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 572/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6979e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 573/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4234e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 574/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.5933e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 575/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8619e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 576/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1720e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 577/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3886e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 578/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2289e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 579/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6122e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 580/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5239e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 581/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3408e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 582/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5820e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 583/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7896e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 584/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8413e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 585/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1730e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 586/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8814e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 587/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6926e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 588/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5921e-04 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 589/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9697e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 590/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8000e-05 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 591/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6207e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 592/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9588e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 593/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8932e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 594/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6149e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 595/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5076e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 596/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3551e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 597/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7963e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 598/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4548e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 599/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9719e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 600/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4603e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 601/10000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5751e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 602/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2806e-07 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 603/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7888e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 604/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8563e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 605/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4352e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 606/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5568e-08 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.9231\n",
      "Epoch 607/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6029e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 608/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7500e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 609/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8368e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 610/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0473e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 611/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6670e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 612/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0142e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 613/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1134e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 614/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8780e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 615/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4306e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 616/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.4897e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1016e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 618/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1824e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 619/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.1834e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 620/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8416e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 621/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3492e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 622/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6319e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 623/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4509e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 624/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0978e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 625/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5761e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 626/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0713e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 627/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7422e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 628/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5021e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 629/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0387e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 630/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5634e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 631/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4374e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 632/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7316e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 633/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3157e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 634/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2785e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 635/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3281e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 636/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.5662e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 637/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6855e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 638/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5839e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 639/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3751e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 640/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5264e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 641/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9670e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 642/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6832e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 643/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9939e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 644/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6371e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 645/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4213e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 646/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6058e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 647/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0897e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 648/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8388e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 649/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7490e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 650/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3111e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 651/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0855e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 652/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.8884e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 653/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4772e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 654/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7801e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 655/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3442e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 656/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5008e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 657/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6500e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 658/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7694e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 659/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.8590e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 660/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6676e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 661/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5839e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 662/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7897e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 663/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.8251e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 664/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4733e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 665/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2382e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 666/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8036e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 667/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3085e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 668/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1487e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 669/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2822e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 670/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4278e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 671/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5921e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 672/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3283e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8214e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 674/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1527e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 675/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3109e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 676/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4209e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 677/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7476e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 678/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8675e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 679/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6655e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 680/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4798e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 681/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6288e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 682/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3557e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 683/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9517e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 684/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7911e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 685/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6565e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 686/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.7806e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 687/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9780e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 688/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1005e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 689/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.7945e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 690/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8700e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 691/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4151e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 692/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5506e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 693/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.5863e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 694/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4357e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 695/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.0873e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 696/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4743e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 697/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1595e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 698/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0736e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 699/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9600e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 700/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3789e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 701/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3826e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 702/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6009e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 703/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4608e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 704/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8193e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 705/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0094e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 706/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8320e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 707/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5537e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 708/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2972e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 709/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.2043e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 710/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3797e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 711/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1669e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 712/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9856e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 713/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1787e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 714/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1391e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 715/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8492e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 716/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6555e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 717/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6051e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 718/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4532e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 719/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4675e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 720/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3946e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 721/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4593e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 722/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3127e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 723/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0622e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 724/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5390e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 725/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5521e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 726/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3657e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 727/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1387e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 728/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2695e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.0942e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 730/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3302e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 731/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9950e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 732/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4223e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 733/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7572e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 734/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3621e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 735/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2095e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 736/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5000e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 737/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4290e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 738/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5000e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 739/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6953e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 740/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2830e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 741/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8522e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 742/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5101e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 743/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3291e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 744/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4551e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 745/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9163e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 746/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4804e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 747/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6181e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 748/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6475e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 749/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3097e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 750/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9542e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 751/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0162e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 752/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4695e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 753/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9785e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 754/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7096e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 755/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1035e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 756/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6298e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 757/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8090e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 758/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.3242e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 759/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0167e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 760/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2996e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 761/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0668e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 762/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3584e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 763/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6371e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 764/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6365e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 765/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3632e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 766/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1410e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 767/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9027e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 768/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2831e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 769/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8378e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 770/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9620e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 771/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5951e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 772/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4324e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 773/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4461e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 774/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4009e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 775/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4819e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 776/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6676e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 777/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5624e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 778/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3802e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 779/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8086e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 780/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6796e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 781/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1035e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 782/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7899e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 783/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8890e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 784/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2803e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5819e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 786/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5714e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 787/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6193e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 788/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3467e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 789/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7568e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 790/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.2058e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 791/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.4359e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 792/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1199e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 793/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7979e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 794/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6416e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 795/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4591e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 796/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1244e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 797/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.5234e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 798/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1297e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 799/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1603e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 800/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6325e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 801/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6367e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 802/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9912e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 803/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4992e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 804/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8761e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 805/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.9954e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 806/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5935e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 807/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3538e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 808/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4003e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 809/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9339e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 810/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4357e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 811/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4415e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 812/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3962e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 813/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.1874e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 814/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3386e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 815/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.7403e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 816/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8240e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 817/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4398e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 818/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8098e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 819/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4208e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 820/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2218e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 821/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0963e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 822/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 823/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1937e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 824/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8810e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 825/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5353e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 826/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6473e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 827/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6395e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 828/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7391e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 829/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6050e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 830/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7322e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 831/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4579e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 832/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4426e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 833/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.3275e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 834/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7806e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 835/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7155e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 836/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6935e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 837/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3540e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 838/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.7803e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 839/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8692e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 840/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3254e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9090e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 842/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9321e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 843/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1674e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 844/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1831e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 845/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5818e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 846/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7318e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 847/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5726e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 848/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9376e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 849/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6927e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 850/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8345e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 851/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6023e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 852/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3343e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 853/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4751e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 854/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9136e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 855/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3638e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 856/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6110e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 857/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2782e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 858/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4480e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 859/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2565e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 860/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7067e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 861/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2616e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 862/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4938e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 863/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1932e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 864/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0985e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 865/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6020e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 866/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4502e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 867/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6079e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 868/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4494e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 869/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.7811e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 870/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0932e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 871/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8588e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 872/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0983e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 873/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5768e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 874/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4116e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 875/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2268e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 876/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7488e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 877/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3286e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 878/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1167e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 879/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.8495e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 880/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4078e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 881/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9880e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 882/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3900e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 883/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7482e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 884/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5114e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 885/10000\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3496e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 886/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3687e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 887/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3463e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 888/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6126e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 889/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7130e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 890/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6673e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 891/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0694e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 892/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2859e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 893/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4564e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 894/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9251e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 895/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5978e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 896/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6676e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.7565e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 898/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6021e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 899/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1241e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 900/10000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8669e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 901/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6966e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 902/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6677e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 903/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5109e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 904/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0908e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 905/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4120e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 906/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3065e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 907/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3613e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 908/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5444e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 909/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1722e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 910/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6482e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 911/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6561e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 912/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6326e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 913/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2756e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 914/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2963e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 915/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1264e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 916/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0638e-05 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 917/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3028e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 918/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2799e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 919/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.3697e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 920/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6726e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 921/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7644e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 922/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2036e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 923/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5804e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 924/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3917e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 925/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5101e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 926/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.5604e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 927/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3420e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 928/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4379e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 929/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9993e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 930/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8970e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 931/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3268e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 932/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3128e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 933/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.9188e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 934/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0221e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 935/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5741e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 936/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6495e-07 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 937/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3476e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 938/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0687e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 939/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9515e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 940/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4883e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 941/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3896e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 942/10000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7418e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n",
      "Epoch 943/10000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0683e-08 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1000-352ad57f7412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train, y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=(x_test, y_test)) \n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#           callbacks=[tensorboard_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_trainable_weights_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2958\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m     \"\"\"\n\u001b[0;32m-> 2960\u001b[0;31m     \u001b[0mtf_keras_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3069\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    870\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/env/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_IterationGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitemref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitemref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32, epochs=10000,\n",
    "          validation_data=(x_test, y_test)) \n",
    "#           callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 79us/step\n",
      "Perda: 141.0605788230896 %\n"
     ]
    }
   ],
   "source": [
    " print(\"Perda: \" + str(100*(model.evaluate(x_test,y_test)[0]))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 41us/step\n",
      "Precisão: 92.30769276618958 %\n"
     ]
    }
   ],
   "source": [
    " print(\"Precisão: \" + str(100*(model.evaluate(x_test,y_test)[1]))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.savefig(\"Perdas.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.savefig(\"Precisao.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Modelo_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 32)                832       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,233\n",
      "Trainable params: 4,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorboard import notebook\n",
    "# notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook.display(port=6006, height=1000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
